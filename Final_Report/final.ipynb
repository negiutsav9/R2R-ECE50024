{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as tvt\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "seed = 0\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.deterministic=True\n",
    "torch.backends.cudnn.benchmarks=False\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrangeDataSIDD(file_path = './data/SIDD_Medium_Srgb/Data', train_ratio=0.8):\n",
    "\n",
    "    print(\"Arranging the SIDD images\")\n",
    "    file_list = os.listdir(file_path)\n",
    "    random.shuffle(file_list)\n",
    "    training_data = {\"noisy\":[], \"gt\":[]}\n",
    "    testing_data = {\"noisy\":[], \"gt\": []}\n",
    "    train_files = file_list[:len(file_list)*train_ratio]\n",
    "    test_files = file_list[len(file_list)*train_ratio : ]\n",
    "\n",
    "    print('Creating training data')\n",
    "    for i in tqdm(range(len(train_files))):\n",
    "        if \"GT_SRGB_010\" in train_files[i]:\n",
    "            gt_img = Image.open(train_files[i]).convert('RGB').resize((512,512))\n",
    "            training_data['gt'].append(gt_img)\n",
    "        if \"NOISY_SRGB_010\" in train_files[i]:\n",
    "            noisy_img = Image.open(train_files[i]).convert('RGB').resize((512,512))\n",
    "            training_data['noisy'].append(noisy_img)\n",
    "    print(\"Number of ground truth images:\",len(training_data['gt']))\n",
    "    print(\"Number of noisy images:\",len(training_data['noisy']))  \n",
    "\n",
    "\n",
    "    print('Creating testing data')\n",
    "    for i in tqdm(range(len(test_files))):\n",
    "        if \"GT_SRGB_010\" in test_files[i]:\n",
    "            gt_img = Image.open(test_files[i]).convert('RGB').resize((512,512))\n",
    "            testing_data['gt'].append(gt_img)\n",
    "        if \"NOISY_SRGB_010\" in test_files[i]:\n",
    "            noisy_img = Image.open(test_files[i]).convert('RGB').resize((512,512))\n",
    "            testing_data['noisy'].append(noisy_img)\n",
    "    print(\"Number of ground truth images:\",len(testing_data['gt']))\n",
    "    print(\"Number of noisy images:\",len(testing_data['noisy']))\n",
    "    \n",
    "    with open('./data_sidd.pkl','wb') as f:\n",
    "        pickle.dump((training_data, testing_data), f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print('Pickle File Created for SIDD Images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrangeDataPolyU(file_path = './data/PolyU-Real-World-Noisy-Images-Dataset-master', train_ratio=0.8):\n",
    "    \n",
    "    print('Arranging the PolyU images')\n",
    "    overall_set = []\n",
    "    file_list = os.listdir(file_path)\n",
    "    for i in range(0,len(file_list),2):\n",
    "        overall_set.append[(file_list[i], file_list[i+1])]\n",
    "    random.shuffle(file_list)\n",
    "    train_files = file_list[:len(file_list)*train_ratio]\n",
    "    test_files = file_list[len(file_list)*train_ratio : ]\n",
    "    training_data = {\"noisy\":[], \"gt\":[]}\n",
    "    testing_data = {\"noisy\":[], \"gt\": []}\n",
    "\n",
    "    print('Creating training data')\n",
    "    for i in range(len(train_files)):\n",
    "        training_data['noisy'].append(Image.open(train_files[i][1]).convert('RGB').resize(512,512))\n",
    "        training_data['gt'].append(Image.open(train_files[i][0]).convert('RGB').resize(512,512))\n",
    "    print(\"Number of ground truth images:\",len(training_data['gt']))\n",
    "    print(\"Number of noisy images:\",len(training_data['noisy']))  \n",
    "    \n",
    "    print('Creating testing data')\n",
    "    for i in range(len(test_files)):\n",
    "        testing_data['noisy'].append(Image.open(test_files[i][1]).convert('RGB').resize(512,512))\n",
    "        testing_data['gt'].append(Image.open(test_files[i][0]).convert('RGB').resize(512,512))\n",
    "    print(\"Number of ground truth images:\",len(testing_data['gt']))\n",
    "    print(\"Number of noisy images:\",len(testing_data['noisy']))\n",
    "\n",
    "    with open('./data_polyu.pkl','wb') as f:\n",
    "        pickle.dump((training_data, testing_data), f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print('Pickle File Created for PolyU Images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        super(ImageDataset, self).__init__()\n",
    "        self.noisyData = data['noisy']\n",
    "        self.gtData = data['gt']\n",
    "        self.transform = tvt.Compose([tvt.ToTensor()])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.noisyData)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.transform(self.noisyData[index]), self.transform(self.gtData[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataLoaders(type):\n",
    "    if type=='SIDD':\n",
    "        if not os.path.isfile('./data_sidd.pkl'):\n",
    "            arrangeDataSIDD()\n",
    "        with open('./data_sidd.pkl', 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        train_dataset = ImageDataset(data[0])\n",
    "        test_dataset = ImageDataset(data[1])\n",
    "        train_DL = DataLoader(train_dataset, batch_size=4, num_workers=2, shuffle=False)\n",
    "        test_DL = DataLoader(test_dataset, batch_size=4, num_workers=2, shuffle=False)\n",
    "        return train_DL, test_DL\n",
    "    if type=='PolyU':\n",
    "        if not os.path.isfile('./data_polyu.pkl'):\n",
    "            arrangeDataSIDD()\n",
    "        with open('./data_polyu.pkl', 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        train_dataset = ImageDataset(data[0])\n",
    "        test_dataset = ImageDataset(data[1])\n",
    "        train_DL = DataLoader(train_dataset, batch_size=4, num_workers=2, shuffle=False)\n",
    "        test_DL = DataLoader(test_dataset, batch_size=4, num_workers=2, shuffle=False)\n",
    "        return train_DL, test_DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dCNN(torch.nn.Module):\n",
    "    def __init__(self, channels, layers=17):\n",
    "        super(dCNN, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(\n",
    "            in_channels=channels, out_channels=64, kernel_size=3, padding=1, bias=False\n",
    "        )\n",
    "        self.convList = torch.nn.ModuleList()\n",
    "        for i in range(layers - 2):\n",
    "            self.convList.append(\n",
    "                torch.nn.Conv2d(\n",
    "                    in_channels=64,\n",
    "                    out_channels=64,\n",
    "                    kernel_size=3,\n",
    "                    padding=1,\n",
    "                    bias=False,\n",
    "                )\n",
    "            )\n",
    "            self.convList.append(torch.nn.BatchNorm2d(64))\n",
    "            self.convList.append(torch.nn.ReLU(inplace=True))\n",
    "        self.conv2 = torch.nn.Conv2d(\n",
    "            in_channels=64, out_channels=channels, kernel_size=3, padding=1, bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.nn.functional.relu(x, inplace=True)\n",
    "        for conv in self.convList:\n",
    "            x = conv(x)\n",
    "        x = self.conv2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check PSNR(dB)/SSIM values of the resulted images\n",
    "def calculate_metrics(image, original, data_range):\n",
    "    image = image.data.cpu().numpy().astype(np.float32)\n",
    "    original = original.data.cpu().numpy().astype(np.float32)\n",
    "    psnr_value = 0\n",
    "    ssim_value = 0\n",
    "    for i in range(image.shape[0]):\n",
    "        psnr_value += psnr(\n",
    "            original[i, :, :, :], image[i, :, :, :], data_range=data_range\n",
    "        )\n",
    "        ssim_value += ssim(\n",
    "            original[i, :, :, :],\n",
    "            image[i, :, :, :],\n",
    "            channel_axis=0,\n",
    "            data_range=data_range,\n",
    "        )\n",
    "    psnr_value /= image.shape[0]\n",
    "    ssim_value /= image.shape[0]\n",
    "\n",
    "    return psnr_value, ssim_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingR2R(model, device, dataloader, epochs, sigma,type):\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    alpha = 0.5\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        psnr_value = 0.0\n",
    "        for idx, data in enumerate(dataloader):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            noisy_image, clean_image = data\n",
    "            noisy_image = noisy_image.to(device)\n",
    "            clean_image = clean_image.to(device)\n",
    "            D = (sigma/255.00) * torch.FloatTensor(noisy_image.size()).normal_(mean=0, std=1.0).cuda()\n",
    "            input = noisy_image + alpha * D\n",
    "            target = noisy_image - D / alpha\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target) / (target.size()[0]*2)\n",
    "            running_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # evaluating the performance per batch\n",
    "            model.eval()\n",
    "            output = torch.clamp(model(noisy_image), 0, 1)\n",
    "            psnr_val, ssim_value = calculate_metrics(output, clean_image, 1.0)\n",
    "            psnr_value += psnr_val\n",
    "            if idx % 50 == 0:\n",
    "                print(\n",
    "                    \"Epoch:\",epoch + 1,\n",
    "                    \"[\",idx + 1,\"/\",\n",
    "                    len(dataloader),\"]\",\n",
    "                    \"=>\",\n",
    "                    \"PSNR:\",psnr_value / 50,\n",
    "                    \"Loss:\",running_loss / 50,\n",
    "                )\n",
    "                running_loss = 0.0\n",
    "                psnr_value = 0.0\n",
    "    file_name = \"R2R_\" + type + \"_model_\" + str(sigma) + \".pth\"\n",
    "    torch.save(model.state_dict(), file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingN2N(model, device, dataloader, epochs, sigma_1, sigma_2, type):\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        psnr_value = 0.0\n",
    "        for idx, data in enumerate(dataloader):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            noisy_image, clean_image = data\n",
    "            noisy_image = noisy_image.to(device)\n",
    "            clean_image = clean_image.to(device)\n",
    "            input = noisy_image + torch.randn(noisy_image.size()) * sigma_1\n",
    "            target = noisy_image + torch.randn(noisy_image.size()) * sigma_2\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target) / (target.size()[0]*2)\n",
    "            running_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # evaluating the performance per batch\n",
    "            model.eval()\n",
    "            output = torch.clamp(model(noisy_image), 0, 1)\n",
    "            psnr_val, ssim_value = calculate_metrics(output, clean_image, 1.0)\n",
    "            psnr_value += psnr_val\n",
    "            if idx % 50 == 0:\n",
    "                print(\n",
    "                    \"Epoch:\",epoch + 1,\n",
    "                    \"[\",idx + 1,\"/\",\n",
    "                    len(dataloader),\"]\",\n",
    "                    \"=>\",\n",
    "                    \"PSNR:\",psnr_value / 50,\n",
    "                    \"Loss:\",running_loss / 50,\n",
    "                )\n",
    "                running_loss = 0.0\n",
    "                psnr_value = 0.0\n",
    "    file_name = \"N2N_\" + type + \"_model_\" + str(sigma_1) + str(sigma_2) + \".pth\"\n",
    "    torch.save(model.state_dict(), file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingN2C(model, device, dataloader, epochs, type):\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        psnr_value = 0.0\n",
    "        for idx, data in enumerate(dataloader):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            noisy_image, clean_image = data\n",
    "            noisy_image = noisy_image.to(device)\n",
    "            clean_image = clean_image.to(device)\n",
    "            input = noisy_image\n",
    "            target = clean_image\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target) / (target.size()[0]*2)\n",
    "            running_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # evaluating the performance per batch\n",
    "            model.eval()\n",
    "            output = torch.clamp(model(noisy_image), 0, 1)\n",
    "            psnr_val, ssim_value = calculate_metrics(output, clean_image, 1.0)\n",
    "            psnr_value += psnr_val\n",
    "            if idx % 50 == 0:\n",
    "                print(\n",
    "                    \"Epoch:\",epoch + 1,\n",
    "                    \"[\",idx + 1,\"/\",\n",
    "                    len(dataloader),\"]\",\n",
    "                    \"=>\",\n",
    "                    \"PSNR:\",psnr_value / 50,\n",
    "                    \"Loss:\",running_loss / 50,\n",
    "                )\n",
    "                running_loss = 0.0\n",
    "                psnr_value = 0.0\n",
    "    file_name = \"N2C_\" + type + \"_model_\" + \".pth\"\n",
    "    torch.save(model.state_dict(), file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def sampleTestingR2R()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def sampleTestingN2N()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def noiseCheckR2R()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def noiseCheckN2N()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Pipeline using SIDD Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Pipeline using PolyU Dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
