# Recorrupted-to-Recorrupted (R2R) deep-learning for image denoising

# Introduction

Image denoising is a practically important problem in the field of image
processing for both casual imaging as well as research-oriented imaging.
Images can come out noisy due to camera settings or environment. The
goal of the paper is to remove the inherent random noises in the images
provided as input. Various supervised and unsupervised machine learning
(ML) techniques currently exist, and in this paper, we explore the
efficiency of a particular ML technique.

Among the current methods, a popular method is deep learning, a subset
of machine learning that employs multi-layer neural networks to learn
and represent complex patterns and relationships in data. Within deep
learning, there are broadly two approaches, namely: Supervised
deep-learning methods, which involve training a DNN (deep neural
network) on a large number of ground-truth (clean) images and their
noisy counterparts, and Unsupervised deep-learning methods, which
involve training a DNN on purely noisy image data sets, without the
corresponding clean images.

Our focus in this paper will be on using a particular type of
unsupervised learning technique, called the Recorrupted-to-Recorrupted
(R2R) deep-learning for image denoising, which was introduced in the
paper titled \"Recorrupted-to-Recorrupted: Unsupervised Deep Learning
for Image Denoising\" by Pang et. al in 2021.

# Drawbacks of Existing Techniques

One issue with the supervised deep learning approach is the requirement
of large 'clean' image datasets for training, which can be
resource-intensive on both material and financial fronts. Moreover, in
practice, obtaining clean images may not be easy, if not impossible.
Another problem is that creating the noisy pair for a clean image is a
non-trivial task.

Unsupervised learning may remove the need for noisy and ground truth
image pairs, but current unsupervised methods do not perform as well as
supervised methods. The paper seeks to solve this issue by creating an
unsupervised denoising technique that performs better than existing
unsupervised methods as well as on par with supervised denoisers.

# R2R Methodology

The R2R method generates a pair of noisy images which are later trained
on a DNN. Notably, the R2R method doesn't require clean images for
training, instead, it uses its unique data augmentation technique for
training. The method of creating a pair of noisy images and calculating
the subsequent loss function by R2R are as follows:

Consider a noisy image represented by $$\begin{aligned}
y &= x + n\end{aligned}$$ where *n* is a Gaussian distribution
$N(0, \bm{\Sigma}_x)$ denoting the noise and *x* is the clear image.
Now, the new pairs of noisy images are generated by
$$\hat{y} = y + Az,\quad \tilde{y} = y-Bz \tag{2}$$ where *z* is sampled
Gaussian distribution $N(0, I)$ while *A* and *B* satisfy the following
condition: $$\math{AB^T = \Sigma_x } \tag{3}$$ where $\Sigma_x$ is the
covariance matrix of the clear image *x*. With the pair
$(\hat{y}, \tilde{y})$ as training data, the solution to the DNN can be
represented as
$$min_\theta L(\theta;A,B) = E_{y,x}\{|| F_\theta (y + Az) - (y-Bz)||^2_2\} \tag{4}$$

# Potential Applications of R2R

The R2R method shows promise for various image-denoising applications.
From enhancing medical diagnoses like X-rays and brain scans to
revealing faint details in astronomical images, R2R's ability to learn
without clean image counterparts opens doors in diverse fields. It can
also improve the quality of photos taken from a phone at night or in
motion, preserve historical archives, and create unique artistic
effects.

In the paper by Pang et. al, the R2R method is applied to evaluate its
ability to remove Additive White Gaussian Noise (AWGN). The R2R is
performed on a gray-scale BSD68 dataset with different noise levels, and
its results are compared with supervised methods trained on the BSD400
dataset. To assess the denoising of real-world images with diverse noise
types, the paper employs the SIDD Benchmark's validation and benchmark
sets, along with real-world noisy images from the CC and PolyU datasets.

# Toy Problem

Using the CIFAR-10 dataset, we wish to remove AWGN with the R2R model.
To do this, we will add zero-mean AWGN at two noise levels ($\sigma$ =
25, 50) like the original paper did to create our training and testing
sets. The training set consists of 50,000 images, and the testing set
has 10,000 images of size 32 x 32. After putting the data through the
R2R model, we will look at the PSNR and SSIM values to determine the
performance of our reconstruction.

# Methods of Re-Implementation

Our re-implementation begins by defining a class to add AWGN to our
images with our selected noise levels. For the creation of our datasets,
we also had to redefine the getitem function of the CIFAR-10 dataset to
output pairs of noisy and clean images. The reconstruction also required
the set up of a DnCNN. Similar to the paper, we set up our DnCNN with 17
convolution layers.

In our training function, we create our pair of noisy images at the
selected noise levels of $\sigma$ = 25, 50. Like the original paper,
training was done for 50 epochs with a batch size of 128. The testing
function outputs the results of our PSNR and SSIM for the problem. A
sample testing function was included to observe these values for an
individual test image. It also displayed the clean and noisy version of
the selected individual image and was run for both noise levels.

# Results of Re-Implementation

For the most part, noise does appear to be much reduced by our DNN, with
a very readable output image. Individual outputs at both noise levels
can be seen in Figures 1 and 2. PSNR (Peak Signal to Noise Ratio) and
SSIM (Structural Similarity Index Measure) are metrics to help define
the similarity between clean and unclean images. Higher is better.

![PSNR = 3.49, SSIM = 0.39 when $\sigma$ =
50](checkpt3_3.1.png){#fig:plane width="6cm"}

![PSNR = 3.49, SSIM = 0.39 when $\sigma$ =
50](checkpt3_4.1.png){#fig:plane width="6cm"}

When comparing to the paper's results, the PSNR and SSIM values are
smaller. The original paper used images of size 180 x 180, which is much
larger than our 32 x 32 images. This would contribute to our values
being so much smaller.

# Areas for Improvement

Not every image came out with optimal values. In some instances, the
PSNR or SSIM came out as negative values. Example images can be seen in
Figures 3 and 4.

![PSNR = 2.49, SSIM = -0.07 when $\sigma$ =
50](checkpt3_badPSNR1.png){#fig:carrrr width="6cm"}

![PSNR = 2.49, SSIM = -0.07 when $\sigma$ =
50](checkpt3_badSSIM1.png){#fig:carrrr width="6cm"}

Our noise also seems to be extreme in our bright whites and deep blacks.
So, our noise function may need to be adjusted. The denoised images also
appear to have a haze over them that we could try to remedy in our
application to a real world problem.

# Bibliography

Kai Zhang, Wangmeng Zuo, Yunjin Chen, Deyu Meng, and Lei Zhang. Beyond a
gaussian denoiser: Residual learning of deep cnn for image denoising.
IEEE Trans. Image Process., 26(7):3142--3155, 2017

Tongyao Pang, Huan Zheng, Yuhui Quan, and Hui Ji.
Recorrupted-to-Recorrupted: Unsupervised Deep Learning for Image
Denoising. IEEE/CVF Conference on Computer Vision and Pattern
Recognition, 2021. DOI: 10.1109/CVPR46437.2021.00208
https://github.com/PangTongyao/Recorrupted-to-Recorrupted-Unsupervised-Deep-Learning-for-Image-Denoising
